{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4082ad75-d882-456d-b6a9-9f2ec93eab90",
   "metadata": {},
   "source": [
    "__contents:__\n",
    "\n",
    "1. [Geometric transformations](#Geometric_transformations)\n",
    "   * 1.1.[Image translation](#Image_translation)\n",
    "   * 1.2.[Rotation](#Rotation)\n",
    "   * 1.3.[Scaling](#Scaling)\n",
    "   * 1.4.[Flipping](#Flipping)\n",
    "   * 1.5.[Shearing](#Shearing)\n",
    "   * 1.6.[Cropping](#Cropping)\n",
    "2. [Arithmetic Operations](#Arithmetic_Operations)\n",
    "   * 2.1.[Addition](#Addition)\n",
    "     - 2.1.1.[weighted addition](#weighted_addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f78b48-6abf-42cb-becf-eeb7f7b0da58",
   "metadata": {},
   "source": [
    "# <h2 style=\"color: blue;\"> 1.Geometric transformations <a id='Geometric_transformations'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed7831-bd36-40b4-8215-f9207c24843b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "In technical terms, image processing involves transforming the coordinates of image points from one coordinate system to another. Using various transformation functions, it is possible to map pixel coordinates in the original image to new coordinates in the transformed image, resulting in different types of transformations.\n",
    "\n",
    "As we move forward with this chapter, we will explore various image transformation techniques, including rotation, scaling, and more, beginning with image translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1121b-8269-4338-8279-fd47ac9e9d71",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.1.Image translation <a id='Image_translation'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9beeac-ec56-4abe-9a4b-67d5e8303800",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image translation is the process of shifting an image in horizontal and vertical directions. Using image translation we can move our image on the x and y axis by a specified amount.\n",
    "\n",
    "To perform image translation, a translation matrix is applied to the image that maps the original coordinates to the new, shifted coordinates. Image translations can be performed by applying affine transformations to an input image.\n",
    "We use the ```cv2.warpAffine``` function in OpenCV to apply affine transformations:\n",
    "```python\n",
    "cv2.warpAffine(src, M, dsize, dst, flags=INTER_LINEAR,borderMode=BORDER_CONSTANT, borderValue=0)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src:``` The source image on which transformations will be applied.\n",
    "* ```M:``` The transformation matrix.\n",
    "* ```dsize:``` Size of the output image.\n",
    "* ```dst:``` dst is an optional output image that stores the result of transformation. The dst image must be of the same size and type as the input image src. If the dst image is not provided, the OpenCV function will create an output image of the same size and type as the input image and return it as the output.\n",
    "* ```Flags:``` It is an optional parameter that specifies the interpolation method to be used.\n",
    "* ```borderMode:``` This specifies how to handle the pixels that fall outside the image boundaries. It is a with default value as ```cv2.BORDER_CONSTANT```.\n",
    "* ```borderValue:``` This is used only with ```cv2.BORDER_CONSTANT``` mode and specifies the constant value used to pad the image. It is an with default value as 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48d431d-09b8-4c85-9008-7c5090d80eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('fruits.png')\n",
    "# Define the translation matrix\n",
    "tx = 50 # x-direction\n",
    "ty = 100 # y-direction\n",
    "M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "# Apply the translation to the image\n",
    "rows, cols, _ = img.shape\n",
    "translated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Translated Image', translated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea6f44-79c8-4ba6-8a26-b95cdca4d074",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.2. Rotation <a id='Rotation'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fa803-bb8a-4ba4-b783-bc73d2886d1b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image rotation is the process of rotating an image by an angle around its center point.There are two ways to perform image rotation:\n",
    "\n",
    "1. ```cv2.rotate```function for image rotation. this function is that it can __only__ rotate the image by ```90 degrees in a clockwise or anticlockwise direction```. It does __not__ allow us to choose an arbitrary angle to rotate the image.\n",
    "```python\n",
    "cv2.rotate(src, rotateCode, dst)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src:``` The source image on which transformations will be applied.\n",
    "* ```rotateCode:``` This parameter specifies the direction and angle in which the image should be rotated. The possible values for rotateCode are:\n",
    "- ```cv2.ROTATE_90_CLOCKWISE:``` Rotates the image 90 degrees in clockwise direction.\n",
    "- ```cv2.ROTATE_90_COUNTERCLOCKWISE:``` Rotates the image 90 degrees in counter clockwise direction.\n",
    "- ```cv2.ROTATE_180:``` Rotates the image by 180 degrees.\n",
    "* ```dst:``` dst is an optional output image that stores the result of transformation.\n",
    "\n",
    "2. using the ```cv2.warpAffine``` function: We use another function, ```cv2.getRotationMatrix2D```, to generate the rotation matrix used with the cv2.warpAffine function.\n",
    "```python\n",
    "cv2.getRotationMatrix2D(center = None, angle, scale = 1)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```center:``` The center point(x,y) of the image rotation. The default value for is None. If a point is not specified, the function will use the center point of the image.\n",
    "* ```angle:``` The angle of rotation in degrees. Positive values indicate counter-clockwise direction, while negative values correspond to clockwise rotation.\n",
    "* ```scale:``` The scale parameters is used to scale the size of the image by a factor. The default value for in 1, which means the output image is the same as the size of the input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2fb2d6-d889-499a-9d12-a1517be1ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_img_90cw = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE) # Rotate clockwise by 90 degrees\n",
    "rot_img_90ccw = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) # Rotate counterclockwise by 90 degrees\n",
    "rot_img_180 = cv2.rotate(img, cv2.ROTATE_180) # Rotate by 180 degrees\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Rotated 90 CW', rot_img_90cw)\n",
    "cv2.imshow('Rotated 90 CCW', rot_img_90ccw)\n",
    "cv2.imshow('Rotated 180', rot_img_180)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83467266-8a7d-4244-94f1-df10809f0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape[:2]\n",
    "# Get rotation matrices.\n",
    "M1 = cv2.getRotationMatrix2D((100,100), 30, 1)\n",
    "M2 = cv2.getRotationMatrix2D((cols/2,rows/2), 45, 2)\n",
    "M3 = cv2.getRotationMatrix2D((cols/2,rows/2), -90, 1)\n",
    "# Perform rotation\n",
    "rotated1 = cv2.warpAffine(img, M1, (cols, rows))\n",
    "rotated2 = cv2.warpAffine(img, M2, (cols, rows))\n",
    "rotated3 = cv2.warpAffine(img, M3, (cols, rows))\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Rotated Image 1', rotated1)\n",
    "cv2.imshow('Rotated Image 2', rotated2)\n",
    "cv2.imshow('Rotated Image 3', rotated3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a822ecf-0d07-474d-8959-c6267c0f9bf8",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "We have used the scaling factor of 2 for our image. Earlier, we discussed the importance of specifying the output image size in the warpAffine function. In this instance, we set the output picture size to match the size of the input image. To obtain our scaled image, we must replace these numbers with new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60cfe2-28cb-41f5-b6d1-4b7784f2673e",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.3.Scaling <a id='Scaling'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5fe12e-aeea-484b-9de6-440700df86fb",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image scaling is a common task in image processing that allows us to resize images according to our requirements. When resizing an image, it is important to maintain the aspect ratio of the image to avoid producing a distorted image.\n",
    "\n",
    "We use the ```cv2.resize()``` function to resize images using OpenCV:\n",
    "```python\n",
    "cv2.resize(src, dst, dsize, fx = 0, fy = 0, interpolation = cv2.INTER_LINEAR)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src:``` The source image on which transformations will be applied.\n",
    "* ```dst:``` dst is an optional output image that stores the result of transformation. \n",
    "* ```dsize:``` The size of the output image after resizing.\n",
    "* ```fx:``` The scaling factor along the horizontal axis.\n",
    "* ```fy:``` The scaling factor along the vertical axis.\n",
    "If dsize __is not specified__, it will automatically be calculated using the scaling factors fx and fy.\n",
    "```python\n",
    "dsize = (int(src.shape[1] * fx), int(src.shape[0] * fy)).\n",
    "```\n",
    "* ```interpolation:``` Interpolation refers to the technique used to estimate the new pixel values after applying geometric transformations. Following values can be used for this parameter:\n",
    "  - ```cv2.INTER_NEAREST:``` nearest neighbor interpolation.\n",
    "  - ```cv2.INTER_LINEAR:``` bilinear interpolation.\n",
    "  - ```cv2.INTER_CUBIC:``` bicubic interpolation over 4×4 pixel neighborhood.\n",
    "  - ```cv2.INTER_AREA:``` resampling using pixel area relation. It is the recommended interpolation method when shrinking an image.\n",
    "  - ```cv2.INTER_LANCZOS4:``` Lanczos interpolation over 8x8 pixel neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13130af-3673-409c-898f-caba6bf5269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(img, (0,0), fx = 0.5, fy = 0.5) # Resize the image to half its size\n",
    "resized_img = cv2.resize(img, (640, 480)) # Resize the image to a specific width and height\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Resized Image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bb5e0-54c8-46b0-866b-e951c0368303",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image scaling can also be implemented using the ```cv2.warpAffine``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8eba97-1679-4a57-9159-0beb9dda127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = (400, 400) # Define the new size\n",
    "# Compute the scaling factors for x and y axis\n",
    "sx = new_size[0]/img.shape[1]\n",
    "sy = new_size[1]/img.shape[0]\n",
    "M = np.float32([[sx, 0, 0], [0, sy, 0]]) # Define the transformation matrix\n",
    "resized_img = cv2.warpAffine(img, M, new_size) # Apply the affine transformation\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Resized Image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c1fe9-6b66-4e4b-83d0-4ab5adb364de",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.4.Flipping <a id='Flipping'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3085d-a2a2-4fde-ad00-ef4943c6b604",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image flipping is used to flip an image horizontally or vertically. We can use the ```cv2.flip``` function to implement image flipping:\n",
    "```python\n",
    "cv2.flip(src, dst, flipCode = 1)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be flipped\n",
    "* ```dst:``` Output Variable\n",
    "* ```flipCode:``` A flag that specifies how to flip the array. The following values can be used with this parameter.\n",
    "  - ```'0':``` Vertical flip. Image is flipped around the x-axis.\n",
    "  - ```'1':``` Horizontal flip. Image is flipped around the y-axis\n",
    "  - ```'-1':``` Image is flipped around both axes\n",
    "The default value for is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2941fc5-77c4-49e0-88b0-df542e822271",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flip = cv2.flip(img, 1) # Flip the image horizontally\n",
    "y_flip = cv2.flip(img, 0)# Flip the image vertically\n",
    "xy_flip = cv2.flip(img, -1)# Flip the image on both axes\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Horizontal flip', x_flip)\n",
    "cv2.imshow('Vertical flip', y_flip)\n",
    "cv2.imshow('Both axes', xy_flip)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8164b-f52f-460c-b0c3-f92a92841f61",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.5.Shearing <a id='Shearing'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2554e9-73ea-4d25-9e27-0bf5505c92ab",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Image Shearing is a linear transformation that distorts an image along one of its axes. When an image is sheared along the x-axis, the pixels in the image are shifted horizontally. \n",
    "We will use the ```cv2.warpAffine``` function to implement image shearing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8dd951e-f1b3-489d-bc2f-aae01ebbd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shearing parameters\n",
    "shear_factor_x = 0.2\n",
    "shear_factor_y = 0.3\n",
    "# Obtain shearing matrices\n",
    "M_x = np.array([[1, shear_factor_x, 0], [0, 1, 0]])\n",
    "M_y = np.array([[1, 0, 0], [shear_factor_y, 1, 0]])\n",
    "# Apply shearing transformations\n",
    "rows, cols = img.shape[:2]\n",
    "sheared_img_x = cv2.warpAffine(img, M_x, (cols + int(rows * shear_factor_x), rows))\n",
    "sheared_img_xy = cv2.warpAffine(sheared_img_x, M_y, (cols + int(rows * shear_factor_x), rows + int(cols * shear_factor_y)))\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Sheared Image (X axis)', sheared_img_x)\n",
    "cv2.imshow('Sheared Image (X and Y axis)', sheared_img_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac5d38-a16c-4ed1-8370-b16243b2d3e2",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.6.Cropping <a id='Cropping'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5f577-1503-4273-a441-d9e15c31cce5",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Image cropping is the process of selecting a rectangular portion of an image. Cropping can be considered a type of geometric transformation, where a section of the source image is removed to produce a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a67f93-bdf8-4de2-ac78-727cc26952a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI coordinates\n",
    "x1, y1 = 100, 100 # top-left corner\n",
    "x2, y2 = 300, 400 # bottom-right corner\n",
    "\n",
    "# Crop image\n",
    "cropped_img = img[y1:y2, x1:x2]\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Cropped Image', cropped_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8d540-024c-4d6a-b589-43685cdfcff2",
   "metadata": {},
   "source": [
    "# <h2 style=\"color: blue;\"> 2.Arithmetic Operations <a id='Arithmetic_Operations'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eca904-b1e3-4d28-ac61-85ff4db31716",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "Arithmetic operations are a fundamental concept in image processing. These operations involve performing basic mathematical operations on images to generate new images with different properties. These operations are performed on the pixel values and allow us to extract useful information from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2301882-9798-46ee-bb4e-70eb8979cd0a",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.1.Addition <a id='Addition'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481e4b4-4f25-4cfb-a530-1dac5c35fc2d",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image addition is a basic arithmetic operation that involves adding pixel values of two or more images to produce a single image.\n",
    "We use the ```cv2.add()``` function to perform addition using the OpenCV library:\n",
    "```python\n",
    "cv2.add(src1, src2, dst, mask, dtype)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src1 and src2:``` The source images to be added. Both images should be of the same type and size.\n",
    "* ```dst:``` Output Variable.\n",
    "* ```mask:``` Masking allows us to choose specific pixels where the operation has to be performed. This is an . If it is left blank, the operation is performed on all the pixels.\n",
    "* ```dtype:``` The data type of the output. This is an optional parameter that defaults to the input data type if left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bb09d1d-6c3f-47a1-961b-8f1b635aec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.add() result:\n",
      " [[110 220 180]\n",
      " [ 90 255 160]\n",
      " [220 255 140]]\n",
      "Numpy addition result:\n",
      " [[110 220 180]\n",
      " [ 90  44 160]\n",
      " [220  24 140]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Initialize two sample 3x3 images\n",
    "img1 = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]], dtype = np.uint8)\n",
    "img2 = np.array([[100, 200, 150], [50, 250, 100], [150, 200, 50]], dtype = np.uint8)\n",
    "# Add the images\n",
    "cv2_add = cv2.add(img1, img2)\n",
    "print('cv2.add() result:\\n', cv2_add)\n",
    "# Add the images using numpy addition\n",
    "numpy_add = img1 + img2\n",
    "print('Numpy addition result:\\n', numpy_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6961fc-5b79-47ac-a982-8b086b0e05ff",
   "metadata": {},
   "source": [
    "### <h2 style=\"color: blue;\"> 2.1.1.weighted addition <a id='weighted_addition'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71ad8d-2a83-42f0-b04c-ce5d70a40ce9",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "the weighted addition of images, which means that each image has a different contribution to the final output, and these contributions are not equal, as shared earlier.\n",
    "\n",
    "We use the ```cv2.addWeighted()``` function for this:\n",
    "```python\n",
    "cv2.addWeighted(src1, alpha = 1.0, src2, beta = 0.0, gamma = 0.0, dst, dtype)\n",
    "```\n",
    "__Parameters:__\n",
    "\n",
    "* ```src1 and src2:``` The source images to be added. Both images should be of the same type and size.\n",
    "* ```alpha:``` Weight of the first image. The range of alpha is 0 to 1, where 0 means the first image will not contribute to the output, and 1 means that the first image will have the maximum contribution to the output. The default value for alpha is 1.\n",
    "* ```beta:``` Weight of the second image. The range of beta is between 0 and 1, similar to the alpha parameters. The default value for beta is 0.\n",
    "* ```gamma:``` A scalar value that can be added to all the pixels after the weighted sum is calculated. This is an with default value as 0.\n",
    "* ```dst:``` Output array.\n",
    "* ```dtype:``` The data type of the output. This is an optional parameter that defaults to the input data type if left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c0bfe5f-42b4-429a-8363-7b468e5de835",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('fruits.png')\n",
    "img2 = cv2.imread('fruits.png')\n",
    "# Add the two images with different weights\n",
    "result = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9d816-ee27-4886-86ca-292ebb03a8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
