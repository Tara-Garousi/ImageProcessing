{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419c26fa-9146-41f4-a21b-498448c6d017",
   "metadata": {},
   "source": [
    "__contents:__\n",
    "\n",
    "1. [Morphological operations on images](#Morphological)\n",
    "   - 1.1. [Erosion](#Erosion)\n",
    "   - 1.2. [Dilation](#Dilation)\n",
    "   - 1.3. [Opening](#Opening)\n",
    "   - 1.4. [Cv2.morphologyex()](#Cv2.morphologyex())\n",
    "   - 1.5. [Closing](#Closing)\n",
    "   - 1.6. [Morphological gradient](#Morphological_gradient)\n",
    "   - 1.7. [Top hat](#TopHat)\n",
    "   - 1.8. [Bottom hat](#BottomHat)\n",
    "2. [Smoothing and Blurring](#SmoothingAndBlurring)\n",
    "   - 2.1. [Average Blurring](#AverageBlurring)\n",
    "   - 2.2. [Median blur](#MedianBlur)\n",
    "   - 2.3. [Gaussian blur](#GaussianBlur)\n",
    "   - 2.4. [Bilateral filter](#BilateralFilter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00df9a3-b53f-44b9-b584-ef442afd1abb",
   "metadata": {},
   "source": [
    "# <h2 style = \"color: blue;\"> 1.Morphological operations on images <a id = 'Morphological'></a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29263205-cdb7-4d0f-812b-7ee6e955863d",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Morphological operations are a fundamental set of operations in image processing that allow us to manipulate the shape and structure of images. Morphological operations are generally performed on binary images. Morphological operations are performed using a structuring element, or kernel, by applying it to an input image and producing a different image as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d3b04-f2c3-4d61-ab12-16a0a039bdfd",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.1.Erosion <a id='Erosion'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47303daa-f465-4574-8b19-ce02c1918b39",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Erosion is a morphological operation that involves reducing the size of the object in an image.\n",
    "We can also use erosion to remove small objects in our image, such as removing salt and pepper noise by eroding the unwanted noise pixels.\n",
    "Erosion works by initializing a structuring element and passing this structuring element over each pixel of the image. The area under the structuring element is considered for the operation:\n",
    "* If all the pixels inside the area are __greater than zero__, then the value is changed to __$255$__.\n",
    "* If the pixels within the area __are not all greater than zero__, they are set to __$0$__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae0235-961e-48cb-b307-1d58c33b3ef4",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "For a better explanation of the concept, we can take a small matrix signifying an image and apply a sample __$3 \\times 3$__ kernel to it. Let us try to visualize how erosion operation works on a __$10 \\times 10$__ matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bdad3-5883-42ae-851b-138dd50a8628",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    \n",
    "  <img src=\"erosion.png\" alt=\"Jupyter Logo\" width=\"500\">\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3be458-c840-4f11-a54d-0d9b5745e7c8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"conv.gif\" alt=\"My GIF\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104ce9e-5da9-4aa6-a4df-8c287b7cd389",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "we use ```cv2.Erode()``` to operate erosion in opencv:\n",
    "```python\n",
    "cv2.erode(src, kernel = '3x3 numpy array with all elements as 1', dst, anchor = (-1,-1), iterations = 1, borderType = cv2.BORDER_CONSTANT, borderValue = 0)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be used for erosion.\n",
    "* ```kernel:``` This is the structuring element to be used for erosion. The default value for this is a __$3 /times 3$__ structuring element with all values set as __$1$__.\n",
    "* ```dst:``` Output variable.\n",
    "* ```anchor:``` The anchor is the pixel used as the reference point for the operation to be performed on the surrounding pixels. This is an optional parameter with a default value of __$(-1 , -1)$__ meaning that the anchor is at the center of the kernel.\n",
    "* ```iterations:``` The number of times erosion will be applied to the image. This is with the default value defined as __$1$__.\n",
    "* ```borderType:``` This is the pixel extrapolation method, an optional parameter with a default value of __cv2.BORDER_CONSTANT__.\n",
    "* ```borderValue:``` This is used only with __cv2.BORDER_CONSTANT__ mode and specifies the constant value used to pad the image. It has a default value of __$0$__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa69e0a-e440-4b61-8ae1-d28be929b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('figErosion.png')\n",
    "# Apply erosion once to remove noise\n",
    "kernel = np.ones((5,5) , np.uint8)\n",
    "img1 = cv2.erode(img , kernel, iterations = 1)\n",
    "# Apply erosion multiple times to show bad result\n",
    "img2 = cv2.erode(img, kernel, iterations = 10)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Erosion', img1)\n",
    "cv2.imshow('Over Erosion', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa980402-91ba-4425-85a5-d37d87081bbd",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.2.Dilation <a id='Dilation'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4240b7cb-ab9a-4750-927d-1b3920ad5219",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Dilation is a morphological operation that involves increasing the size of the object in the image. It is the opposite of erosion. Dilation can be used to enhance the boundaries of an object in an image or fill the gaps between two objects. dilation increases the size of an object by adding pixels near the boundaries of that object.\n",
    "Similar to erosion, dilation also works by initializing a structuring element and passing this structuring element over each pixel of the image. The area of the image lying under the structuring element is operated:\n",
    "* If any of the pixels inside are greater than __$0$__, then the value is changed to __$255$__.\n",
    "* If there are no pixels inside the area of the structuring element, the point is set to __$0$__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafc571-3b63-47c0-8ac1-add9de891657",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    \n",
    "  <img src=\"dilation.png\" alt=\"Jupyter Logo\" width=\"500\">\n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb184ddf-bc4a-4100-a4df-358fe954d9ca",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "we use ```cv2.Dilate()``` to operate dilation as below:\n",
    "```python\n",
    "cv2.dilate(src, kernel = '3x3 numpy array with all elements as 1' , dst , anchor = (-1,-1), iterations = 1 , borderType = cv2.BORDER_CONSTANT, borderValue = 0)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be used for erosion.\n",
    "* ```kernel:``` This is the structuring element to be used for erosion. The default value for this is a __$3 /times 3$__ structuring element with all values set as __$1$__.\n",
    "* ```dst:``` Output variable.\n",
    "* ```anchor:``` The anchor is the pixel used as the reference point for the operation to be performed on the surrounding pixels. This is an optional parameter with a default value of __$(-1 , -1)$__ meaning that the anchor is at the center of the kernel.\n",
    "* ```iterations:``` The number of times erosion will be applied to the image. This is with the default value defined as 1.\n",
    "* ```borderType:``` This is the pixel extrapolation method, an optional parameter with a default value of ```cv2.BORDER_CONSTANT```.\n",
    "* ```borderValue:``` This is used only with ```cv2.BORDER_CONSTANT``` mode and specifies the constant value used to pad the image. It has a default value of __$0$__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3e6f83-0e3a-4f69-8ed0-9012b1b0de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('figDilation.png')\n",
    "# Apply erosion once to remove noise\n",
    "kernel = np.ones((5,5) , np.uint8)\n",
    "img1 = cv2.dilate(img, kernel, iterations = 1)\n",
    "# Apply erosion multiple times to show bad result\n",
    "img2 = cv2.dilate(img, kernel, iterations = 5)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Dilation', img1)\n",
    "cv2.imshow('Over Dilation', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8343375-bb11-474c-8835-b2fd9efbf10f",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.3.Opening <a id='Opening'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48dd7c-8ce8-4739-a27a-6528bf18d976",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Opening is a morphological operation that is a sequence of erosion and dilation operations. Erosion followed by Dilation is referred to as an opening operation in image processing.\n",
    "Performing erosion first on the image will result in the removal of small objects or noise in the image. Following this, the dilation operation will close any gaps that have been unintentionally caused due to the erosion operation before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e7d77f-384a-49ae-896f-7ad4942f6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 300x300 image with a black background\n",
    "img = np.zeros((200, 450), np.uint8)\n",
    "# Draw the text “OPENING” on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, 'OPENING', (15, 125), font , 3 , (255, 255, 255) , 5)\n",
    "# Add noise to the image\n",
    "noise = np.zeros((200, 450), np.uint8)\n",
    "cv2.randn(noise, 0, 50)\n",
    "noisy = cv2.add(img, noise)\n",
    "# Define a 5x5 kernel for the erosion and dilation operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "# Perform erosion\n",
    "erosion = cv2.erode(img, kernel, iterations = 1)\n",
    "# Perform dilation on eroded image\n",
    "opening = cv2.dilate(erosion, kernel, iterations = 1)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Noisy Image', noisy)\n",
    "cv2.imshow('erosion', erosion)\n",
    "cv2.imshow('Opening Result', opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304e488-16d3-41e4-b8ff-e356c6cc9450",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.4.Cv2.morphologyex() <a id = 'Cv2.morphologyex()'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b869326-a7a1-4de7-92d3-83c7afd68a8b",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "We will now use the inbuilt opening function to implement this operation in a single line. The ```cv2.Morphologyex()``` function enables us to do this operation.\n",
    "```python\n",
    "cv2.morphologyEx(src, dst, op, kernel, anchor = (-1,-1), iterations = 1, borderType = cv2.BORDER_CONSTANT, borderValue = 0)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be used for erosion.\n",
    "* ```dst:``` Output variable.\n",
    "* ```op:``` This specifies the type of operation to be performed in the image. The possible values for this parameter are:\n",
    "  - ```cv2.MORPH_OPEN:``` opening operation\n",
    "  - ```cv2.MORPH_CLOSE:``` closing operation\n",
    "  - ```cv2.MORPH_GRADIENT:``` morphological gradient\n",
    "  - ```cv2.MORPH_TOPHAT:``` top hat transform\n",
    "  - ```cv2.MORPH_BLACKHAT:``` black hat transform\n",
    "* ```kernel:``` This is the structuring element to be used for erosion. The default value is a __$3 /times 3$__ structuring element with all values set as __$1$__.\n",
    "* ```anchor:``` Reference point for the operation. This is an optional parameter with a default value of __$(-1,-1)$__ meaning that the anchor is at the of the kernel.\n",
    "* ```iterations:``` The number of times erosion will be applied to the image. This is with the default value defined as __$1$__.\n",
    "__$borderType:$__ This is the pixel extrapolation method, an optional parameter with a default value of __cv2.BORDER_CONSTANT__.\n",
    "* ```borderValue:``` This is used only with __cv2.BORDER_CONSTANT__ mode and specifies the constant value used to pad the image. It has a default value of __$0$__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add1d197-7f2d-4db8-82e8-c3684a1a00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 300x300 image with a black background\n",
    "img = np.zeros((200, 450), np.uint8)\n",
    "# Draw the text “OPENING” on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, 'OPENING', (15, 125), font, 3, (255, 255, 255), 5)\n",
    "# Add noise to the image\n",
    "noise = np.zeros((200, 450), np.uint8)\n",
    "cv2.randn(noise, 0, 50)\n",
    "img2 = cv2.add(img, noise)\n",
    "# Define a 5x5 kernel for the opening operation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "# Perform the opening operation on the image\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Noisy Image', img2)\n",
    "cv2.imshow('Opening Result', opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a291c-8594-4ea7-a98c-1f1ea2df8e14",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.5.Closing <a id='Closing'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590f3e0-01d4-4d3d-b6a8-fa2be14acd1d",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Closing is a morphological operation that is a sequence of dilation and erosion operations. Dilation followed by erosion is referred to as a closing operation in image processing. It is called a closing operation because it closes the gaps and holes in an object within an image by expanding the object.We can use the aforementioned __cv2.morphologyEx__ function as this will allow us to implement the operation in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0b80c7-e645-445e-981e-04e2e8c56a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((200, 450), np.uint8)\n",
    "# Draw the text “CLOSING” on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, 'CLOSING', (15, 125), font, 3, (255, 255, 255), 5)\n",
    "noisy_img = img.copy()\n",
    "# Create noise using difference of two images\n",
    "noise = np.zeros_like(img)\n",
    "for I in range(1000):\n",
    "    x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "    cv2.circle(noisy_img, (x, y), 1, (0, 0, 0), -1, lineType=cv2.LINE_AA)\n",
    "# Define kernel for closing operation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "# Perform closing operation\n",
    "dilated_img = cv2.dilate(noisy_img, kernel)\n",
    "closed_img = cv2.erode(dilated_img, kernel)\n",
    "cv2.imshow('Original Imag',img)\n",
    "cv2.imshow('Noisy Imag', noisy_img)\n",
    "cv2.imshow('Dilate', dilated_img)\n",
    "cv2.imshow('Close', closed_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1128b8-fb8c-4ae2-83e8-12b4cf1b3651",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "We can also use the __cv2.morphologyEx()__ function with the __MORPH_CLOSE__ parameter to perform the closing operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae95efc6-4846-4d7b-aaeb-384fa26e91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((200, 450), np.uint8)\n",
    "# Draw the text “OPENING” on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, 'CLOSING', (15, 125), font, 3, (255, 255, 255), 5)\n",
    "noisy_img = img.copy()\n",
    "# Create noise using difference of two images\n",
    "noise = np.zeros_like(img)\n",
    "for i in range(1000):\n",
    "    x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "    cv2.circle(noisy_img, (x, y), 1, (0, 0, 0), -1, lineType = cv2.LINE_AA)\n",
    "# Define kernel for closing operation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "# Apply closing operation\n",
    "closed_img = cv2.morphologyEx(noisy_img, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Noisy Image', noisy_img)\n",
    "cv2.imshow('Closed', closed_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d867b-351d-407e-8e8c-04627fc1e4a9",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.6.Morphological gradient <a id='Morphological_gradient'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07011c-f660-436e-a002-2b49eb7e7b45",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "The morphological gradient is the difference between dilation and erosion operations on an image.Both operations are applied to the source image and the gradient is calculated by subtracting the eroded image from the dilated image. Our object, in reference to the dilated image, will have been expanded while our object in the eroded image would have been reduced in size. By subtracting the images, we end up with the boundary of our object in the image.The morphological gradient can be expressed as follows:\n",
    "__$Morphological Gradient (G) = Dilation (D) - Erosion (E)$__\n",
    "Where:\n",
    "- __Dilation (D)__ is the result of the dilation operation on the input image.\n",
    "- __Erosion (E)__ is the result of the erosion operation on the input image.\n",
    "- __Morphological Gradient (G)__ represents the difference between the dilation and erosion results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18188556-5c0d-4497-8ca5-f733cb2c10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input image\n",
    "img = cv2.imread('MorGradient.png', 0)\n",
    "# Define the kernel\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "# Apply morphological gradient\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "# Display the result\n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('Morphological Gradient', gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a3aeb-9a71-4776-8d48-ab7434618b6c",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.7.Top hat <a id='TopHat'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6602472-a067-48be-b88f-467c8825c565",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "The Top hat operation, also known as the white hat operation, is used to highlight the bright regions in an image. The Top hat operation is the difference between the opening of an image and the original image. We will use the __cv2.morphologyEx__ function with the __cv2.MORPH_TOPHAT__ parameter in the operation type parameters to perform top hat operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7a658e-53f6-463f-9d69-05c440a9104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input image in grayscale\n",
    "img = cv2.imread('TopHat.png', cv2.IMREAD_GRAYSCALE)\n",
    "# Define a rectangular structuring element for the top hat operation\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "# Perform the top hat operation\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Top Hat Result', tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9671dc-5867-462b-9185-f199025f64dc",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 1.8.Bottom hat <a id='BottomHat'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66686644-35e4-4fe0-9a4b-4ec82df2a71f",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "The bottom hat operation, also known as the black hat operation, is the opposite of the top hat operation and is used to highlight the dark regions of an image. The top hat operation is the difference between the closing of an image and the original image. We will use the __cv2.morphologyEx__ function with the __cv2.MORPH_BLACKHAT__ parameter in the operation type parameters to perform bottom hat operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10df7097-0dd6-4b54-b675-8ae2f5fa18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input image in grayscale\n",
    "img = cv2.imread('BottomHat.png', cv2.IMREAD_GRAYSCALE)\n",
    "# Define a rectangular structuring element for the top hat operation\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "# Perform the top hat operation\n",
    "bottomhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Top Hat Result', bottomhat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a11051-8934-491f-bdf8-270fb826668a",
   "metadata": {},
   "source": [
    "# <h2 style=\"color: blue;\"> 2.Smoothing and blurring <a id='SmoothingAndBlurring'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17c4fe-2591-4671-89bc-96b0e44463fc",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Image smoothing and blurring are similar techniques in image processing used to remove noise or reduce sharpness from images.\n",
    "- Image smoothing is the process of removing noise from an image while preserving the edges inside the image.\n",
    "- Image blurring is the process of reducing the sharpness of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3aaa69-e3af-4e8a-8947-57abf3545e4f",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.1.Average Blurring <a id='AverageBlurring'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20088f-a057-47a6-b5c3-268cf154d2eb",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Average blurring is a type of blurring where the value of each pixel is replaced by the average value of pixels surrounding it. The average filter, also called a box filter, is a linear filter used to implement average blurring. The values for each pixel in this filter are the same and the sum of coefficients in this filter is equal to 1.Let us compare two kernels of sizes 3 and 7:\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"KernelBlur.png\" alt=\"Jupyter Logo\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "The __$3 \\times 3$__ kernel will result in a less blurred image than the __$7 \\times 7$__ kernel.Let us demonstrate how a 3x3 averaging filter is applied to a 9x9 image:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    \n",
    "  <img src=\"ConvBlur.png\" alt=\"Jupyter Logo\" width=\"500\">\n",
    "  \n",
    "</div>\n",
    "\n",
    "We will use the __cv2.blur__ function to implement blurring.\n",
    "```python\n",
    "cv2.blur(src, ksize = (3,3), dst, anchor = (-1,-1), borderType = 'cv2.BORDER_DEFAULT')\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be blurred.\n",
    "* ```kernel:``` Size of the kernel to be used for the average filter. This is an optional parameter. The default value for this is a __$3 \\times 3$__ filter with each value equal to __$1/9$__.\n",
    "* ```dst:``` Output variable.\n",
    "* ```anchor:``` The anchor is the pixel used as the reference point for the operation to be performed on the surrounding pixels. This is an optional parameter with a default value of __$(-1,-1)$__ meaning that the anchor is at the of the kernel.\n",
    "* ```borderType:``` This is the pixel extrapolation method, an optional parameter with a default value of __cv2.BORDER_CONSTANT__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d644582-68b3-46fa-baf1-1d2a4666ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('BlurImg.png')\n",
    "# Apply average blurring with kernel size 3\n",
    "blurred_3 = cv2.blur(img, (3, 3))\n",
    "# Apply average blurring with kernel size 7\n",
    "blurred_7 = cv2.blur(img, (7, 7))\n",
    "# Apply average blurring with kernel size 15\n",
    "blurred_15 = cv2.blur(img, (15, 15))\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('blurred (3,3)', blurred_3)\n",
    "cv2.imshow('blurred (7,7)', blurred_7)\n",
    "cv2.imshow('blurred (15,15)', blurred_15)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18b0cd-6121-42df-af16-db0cf21bf8b3",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.2.Median Blur <a id='MedianBlur'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681d669-2e34-410d-9dae-b9afd135d8ba",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Unlike average blurring, where we take the average value of the surrounding pixels, in median blurring the median value of the pixels inside the kernel region is used for the center pixel. Median blurring has a major advantage over average blurring in that the edges are often preserved during median blurring, which is not the case when taking the average value of the whole kernel. We use the __cv2.medianBlur()__ function to implement median blurring in our code.\n",
    "```python\n",
    "cv2.medianBlur(src, ksize, dst)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be blurred.\n",
    "* ```kernel:``` Size of the kernel to be used for the average filter. Note: Unlike _cv2.blur()_, __cv2.medianBlur()__ takes an integer as input to denote the size of the square, rather than the full filter size.\n",
    "* ```dst:``` Output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec46289-f417-4299-a9c6-eea759eed6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('BlurImg.png')\n",
    "# Apply median blur with kernel size 3x3\n",
    "median_3 = cv2.medianBlur(img, 3)\n",
    "# Apply median blur with kernel size 7x7\n",
    "median_7 = cv2.medianBlur(img, 7)\n",
    "# Apply median blur with kernel size 15x15\n",
    "median_15 = cv2.medianBlur(img, 15)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Median Blur 3', median_3)\n",
    "cv2.imshow('Median Blur 7', median_7)\n",
    "cv2.imshow('Median Blur 15', median_15)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ba1da-cbc5-462e-af1b-1dfa365595f5",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "Median blur is particularly useful in removing __salt and pepper noise__ from the image. It is a noise containing randomly occurring white and black pixels in an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dda3ad9-cda0-485b-aeed-b74eab7849ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_img = cv2.imread('SaltPepper.png')\n",
    "# Apply Median Blur\n",
    "denoised_img = cv2.medianBlur(noisy_img, 3)\n",
    "cv2.imshow('Noisy Image', noisy_img)\n",
    "cv2.imshow('Denoised Image', denoised_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856bb0e2-2068-4a9f-a711-d2f68fd72615",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.3.Gaussian Blur <a id='GaussianBlur'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd433a-e5b4-476e-9dcf-8ae268253cb5",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "\n",
    "Gaussian blurring uses a special type of kernel called the Gaussian kernel for the process. The Gaussian kernel is defined using the formula: \n",
    "$$ G(x, y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$$\n",
    "__$X$__ and __$y$__ are the coordinates of each matrix and sigma defines the standard deviation that controls the width of the distribution. A higher value of sigma produces a wider distribution, resulting in more smoothing or blurring of the image. Based on the preceding formula, a Gaussian kernel of size 5 with a sigma value of 1.5 will look like this:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    \n",
    "  <img src=\"GausianKernel.png\" alt=\"Jupyter Logo\" width=\"400\">\n",
    "  \n",
    "</div>\n",
    "\n",
    "We use the __cv2.gaussianBlur()__ function to implement Gaussian blurring in our code.\n",
    "```python\n",
    "cv2.gaussianblur(src, ksize=0, dst, sigmaX=0, sigmaY=0, borderType=’cv2.BORDER_DEFAULT’)\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be blurred.\n",
    "* ```ksize:``` Kernel size of the gaussian kernel. This value is a tuple. The default value is __$(0,0)$__ which means that the size is computed based on the sigmaX and sigmaY values.\n",
    "* ```dst:``` Output variable.\n",
    "* ```sigmaX:``` The standard deviation of the Gaussian kernel in the X direction. It is an optional parameter, and the default value is 0. In case of 0, it will be calculated based on kernel size.\n",
    "* ```sigmaY:``` The standard deviation of the Gaussian kernel in the Y direction. It is an optional parameter with a default value of 0. In case of 0, it will be made equal to the sigmaX value.\n",
    "* ```borderType:``` This is the pixel extrapolation method, an optional parameter with a default value of __cv2.BORDER_CONSTANT__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e15d187-beb5-4a80-b8c7-f0426f8c5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('GaussianBlur.png')\n",
    "# apply Gaussian blur with kernel size (5,5) and standard deviation of 0\n",
    "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "# display the original and blurred images side by side\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Gaussian Blurred Image', gaussian_blur)\n",
    "# wait for a key press and then close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea83108-711d-4205-bf71-c52a2ed62e81",
   "metadata": {},
   "source": [
    "## <h2 style=\"color: blue;\"> 2.4.Bilateral filter <a id='BilateralFilter'></a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ca727-1685-4c39-a40a-8ad1c05d5806",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "    \n",
    "A bilateral filter is a non-linear filter that allows us to blur images while preserving the edges of objects in the image. This makes it a popular choice for a wide range of image processing applications such as denoising and edge detection. By applying separate Gaussian functions to the two parameters, the bilateral filter will help us by being able to balance the importance of spatial distance and intensity difference in the computation of the weighted average:\n",
    "$$ \\text{BF}[I]_p = \\frac{1}{W_p} \\sum_{q \\in S} G_{\\sigma_s}(\\|p - q\\|) G_{\\sigma_r}(I_p - I_q) I_q $$\n",
    "The bilateral filter is implemented using the __cv2.bilateralFIlter()__ function in OpenCV.\n",
    "```python\n",
    "cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace, dst, borderType = 'cv2.BORDER_DEFAULT')\n",
    "```\n",
    "__Parameters:__\n",
    "* ```src:``` The source image to be blurred.\n",
    "* ```d:``` This is the diameter of the pixel neighborhood to be used in the bilateral filter.\n",
    "* ```sigmaColor:``` Standard deviation value of the bilateral filter in the color space. A larger value will mean that pixels with large differences in intensity values will be mixed.\n",
    "sigmaSpace: Standard deviation value of the bilateral filter in the coordinate space. A larger value will mean that pixels with large differences in distance will be mixed.\n",
    "* ```dst:``` Output variable.\n",
    "* ```borderType:``` This is the pixel extrapolation method, an optional parameter with a default value of __cv2.BORDER_CONSTANT__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a519236c-2e39-400d-b173-34927c4376de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Bilateral.png')\n",
    "# Apply bilateral filter with high sigma values\n",
    "filtered_img_high = cv2.bilateralFilter(img, 15, 200, 200)\n",
    "# Apply bilateral filter with low sigma values\n",
    "filtered_img_low = cv2.bilateralFilter(img, 15, 50, 50)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Filtered (high)', filtered_img_high)\n",
    "cv2.imshow('Filtered (low)', filtered_img_low)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24556102-9f0d-49f9-a4b2-3143327f4c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
